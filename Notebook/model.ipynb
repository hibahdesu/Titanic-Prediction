{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data before transformation: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of Transformed df is: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Training RandomForest with pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1447230665.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy: 0.7207\n",
      "\n",
      "Training LogisticRegression with pipeline...\n",
      "LogisticRegression Accuracy: 0.7318\n",
      "\n",
      "Training SVC with pipeline...\n",
      "SVC Accuracy: 0.7430\n",
      "\n",
      "Training KNeighbors with pipeline...\n",
      "KNeighbors Accuracy: 0.7095\n",
      "\n",
      "Best Model: SVC with accuracy: 0.7430\n",
      "Saving model of type: <class 'sklearn.pipeline.Pipeline'>\n",
      "\n",
      "Transformed data preview:\n",
      "    Age     Fare  Parch  Pclass  SibSp  Survived\n",
      "0  22.0   7.2500      0       3      1         0\n",
      "1  38.0  71.2833      0       1      1         1\n",
      "2  26.0   7.9250      0       3      0         1\n",
      "3  35.0  53.1000      0       1      1         1\n",
      "4  35.0   8.0500      0       3      0         0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Select number columns (features)\n",
    "def select_number_columns(df: DataFrame) -> DataFrame:\n",
    "    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n",
    "\n",
    "# Fill missing values with the median\n",
    "def fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n",
    "    for col in df.columns:\n",
    "        values = sorted(df[col].dropna().tolist())\n",
    "        median_value = values[math.floor(len(values) / 2)]\n",
    "        df[[col]] = df[[col]].fillna(median_value)\n",
    "    return df\n",
    "\n",
    "# Function to transform data\n",
    "def transform_df(df: DataFrame) -> DataFrame:\n",
    "    print(f\"Type of data before transformation: {type(df)}\")\n",
    "    assert isinstance(df, pd.DataFrame), f\"Input data is not a DataFrame! Type: {type(df)}\"\n",
    "    transformed_df = fill_missing_values_with_median(select_number_columns(df))\n",
    "    assert isinstance(transformed_df, pd.DataFrame), f\"Output of transform_df is not a DataFrame! Type: {type(transformed_df)}\"\n",
    "    print(f\"Type of Transformed df is: {type(transformed_df)}\")\n",
    "    return transformed_df\n",
    "\n",
    "# Model training function with pipeline\n",
    "def train_models(df: DataFrame):\n",
    "    # Split data into features (X) and target (y)\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models and create a pipeline\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "        'SVC': SVC(),\n",
    "        'KNeighbors': KNeighborsClassifier()\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    # Iterate through each model and evaluate performance using a pipeline\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name} with pipeline...\")\n",
    "\n",
    "        # Create a pipeline that first scales data and then applies the model\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('classifier', model)          # Model training\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Save the best model\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = pipeline\n",
    "            best_model_name = model_name\n",
    "\n",
    "    print(f\"\\nBest Model: {best_model_name} with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Save the best model to a file\n",
    "    joblib.dump(best_model, 'best_titanic_model_with_pipeline.pkl')\n",
    "    print(f\"Saving model of type: {type(best_model)}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Apply transformations and train models\n",
    "df_transformed = transform_df(df)\n",
    "best_model = train_models(df_transformed)\n",
    "\n",
    "# Optional: Test output (e.g., print first few rows of the transformed data)\n",
    "print(\"\\nTransformed data preview:\")\n",
    "print(df_transformed.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data before transformation: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of Transformed df is: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Training RandomForest with pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\1096819291.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 632744194449365604",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Apply transformations and train models\u001b[39;00m\n\u001b[0;32m    113\u001b[0m df_transformed \u001b[38;5;241m=\u001b[39m transform_df(df)\n\u001b[1;32m--> 114\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Optional: Test output (e.g., print first few rows of the transformed data)\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTransformed data preview:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 77\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     71\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([ \n\u001b[0;32m     72\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),  \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, model)          \u001b[38;5;66;03m# Model training\u001b[39;00m\n\u001b[0;32m     74\u001b[0m ])\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Start MLflow run for each model\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Log model parameters\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_params(model\u001b[38;5;241m.\u001b[39mget_params())\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:446\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    442\u001b[0m         user_specified_tags[MLFLOW_RUN_NAME] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m    444\u001b[0m     resolved_tags \u001b[38;5;241m=\u001b[39m context_registry\u001b[38;5;241m.\u001b[39mresolve_tags(user_specified_tags)\n\u001b[1;32m--> 446\u001b[0m     active_run_obj \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     log_system_metrics \u001b[38;5;241m=\u001b[39m MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\tracking\\client.py:393\u001b[0m, in \u001b[0;36mMlflowClient.create_run\u001b[1;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_run\u001b[39m(\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    341\u001b[0m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m     run_name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    345\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Run:\n\u001b[0;32m    346\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m        status: RUNNING\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:169\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_run\u001b[1;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[0;32m    167\u001b[0m user_id \u001b[38;5;241m=\u001b[39m tags\u001b[38;5;241m.\u001b[39mget(MLFLOW_USER, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:212\u001b[0m, in \u001b[0;36mRestStore.create_run\u001b[1;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[0;32m    202\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[0;32m    203\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[0;32m    204\u001b[0m     CreateRun(\n\u001b[0;32m    205\u001b[0m         experiment_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(experiment_id),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    210\u001b[0m     )\n\u001b[0;32m    211\u001b[0m )\n\u001b[1;32m--> 212\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Run\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mrun)\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:82\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[1;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[0;32m     80\u001b[0m     endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[0;32m     81\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:379\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[1;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[0;32m    376\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[0;32m    377\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[1;32m--> 379\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m response_to_parse \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    381\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response_to_parse)\n",
      "File \u001b[1;32mc:\\Users\\habob\\Downloads\\Qafza MLOPs\\week7\\Titanic Prediction\\src\\Normal pipelines\\myenv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:249\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[1;34m(response, endpoint)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[1;32m--> 249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m         )\n",
      "\u001b[1;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: Could not find experiment with ID 632744194449365604"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Select number columns (features)\n",
    "def select_number_columns(df: DataFrame) -> DataFrame:\n",
    "    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n",
    "\n",
    "# Fill missing values with the median\n",
    "def fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n",
    "    for col in df.columns:\n",
    "        values = sorted(df[col].dropna().tolist())\n",
    "        median_value = values[math.floor(len(values) / 2)]\n",
    "        df[[col]] = df[[col]].fillna(median_value)\n",
    "    return df\n",
    "\n",
    "# Function to transform data\n",
    "def transform_df(df: DataFrame) -> DataFrame:\n",
    "    print(f\"Type of data before transformation: {type(df)}\")\n",
    "    assert isinstance(df, pd.DataFrame), f\"Input data is not a DataFrame! Type: {type(df)}\"\n",
    "    transformed_df = fill_missing_values_with_median(select_number_columns(df))\n",
    "    assert isinstance(transformed_df, pd.DataFrame), f\"Output of transform_df is not a DataFrame! Type: {type(transformed_df)}\"\n",
    "    print(f\"Type of Transformed df is: {type(transformed_df)}\")\n",
    "    return transformed_df\n",
    "\n",
    "# Model training function with pipeline\n",
    "def train_models(df: DataFrame):\n",
    "    # Split data into features (X) and target (y)\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    y = df['Survived']\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define models and create a pipeline\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(),\n",
    "        'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "        'SVC': SVC(),\n",
    "        'KNeighbors': KNeighborsClassifier()\n",
    "    }\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_model_name = \"\"\n",
    "\n",
    "    # Initialize MLflow experiment\n",
    "    mlflow.set_experiment(\"Titanic_Model_Experiment\")\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")  # Update with your MLflow server URI if necessary\n",
    "\n",
    "    # Iterate through each model and evaluate performance using a pipeline\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name} with pipeline...\")\n",
    "\n",
    "        # Create a pipeline that first scales data and then applies the model\n",
    "        pipeline = Pipeline([ \n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('classifier', model)          # Model training\n",
    "        ])\n",
    "\n",
    "        # Start MLflow run for each model\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            # Log model parameters\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "            # Train the model\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "            # Evaluate the model\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            # Log metrics for the model\n",
    "            mlflow.log_metrics({\n",
    "                'accuracy': accuracy,\n",
    "            })\n",
    "\n",
    "            # Log the trained model to MLflow\n",
    "            mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "\n",
    "            # Save the best model\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = pipeline\n",
    "                best_model_name = model_name\n",
    "\n",
    "    print(f\"\\nBest Model: {best_model_name} with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "    # Optionally save the best model locally\n",
    "    joblib.dump(best_model, 'best_titanic_model_with_pipeline.pkl')\n",
    "    print(f\"Saving model of type: {type(best_model)}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Apply transformations and train models\n",
    "df_transformed = transform_df(df)\n",
    "best_model = train_models(df_transformed)\n",
    "\n",
    "# Optional: Test output (e.g., print first few rows of the transformed data)\n",
    "print(\"\\nTransformed data preview:\")\n",
    "print(df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv?raw=True'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Select number columns (features)\n",
    "def select_number_columns(df: DataFrame) -> DataFrame:\n",
    "    return df[['Age', 'Fare', 'Parch', 'Pclass', 'SibSp', 'Survived']]\n",
    "\n",
    "# Fill missing values with the median\n",
    "def fill_missing_values_with_median(df: DataFrame) -> DataFrame:\n",
    "    for col in df.columns:\n",
    "        values = sorted(df[col].dropna().tolist())\n",
    "        median_value = values[math.floor(len(values) / 2)]\n",
    "        df[[col]] = df[[col]].fillna(median_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform data\n",
    "def transform_df(df: DataFrame) -> DataFrame:\n",
    "    print(f\"Type of data before transformation: {type(df)}\")\n",
    "    assert isinstance(df, pd.DataFrame), f\"Input data is not a DataFrame! Type: {type(df)}\"\n",
    "    transformed_df = fill_missing_values_with_median(select_number_columns(df))\n",
    "    assert isinstance(transformed_df, pd.DataFrame), f\"Output of transform_df is not a DataFrame! Type: {type(transformed_df)}\"\n",
    "    print(f\"Type of Transformed df is: {type(transformed_df)}\")\n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of data before transformation: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of Transformed df is: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n",
      "C:\\Users\\habob\\AppData\\Local\\Temp\\ipykernel_24592\\2363447678.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[col]] = df[[col]].fillna(median_value)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>19.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>28.0</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>32.0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age     Fare  Parch  Pclass  SibSp  Survived\n",
       "0    22.0   7.2500      0       3      1         0\n",
       "1    38.0  71.2833      0       1      1         1\n",
       "2    26.0   7.9250      0       3      0         1\n",
       "3    35.0  53.1000      0       1      1         1\n",
       "4    35.0   8.0500      0       3      0         0\n",
       "..    ...      ...    ...     ...    ...       ...\n",
       "886  27.0  13.0000      0       2      0         0\n",
       "887  19.0  30.0000      0       1      0         1\n",
       "888  28.0  23.4500      2       3      1         0\n",
       "889  26.0  30.0000      0       1      0         1\n",
       "890  32.0   7.7500      0       3      0         0\n",
       "\n",
       "[891 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply transformations and train models\n",
    "df_transformed = transform_df(df)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_transformed.drop('Survived', axis=1)\n",
    "y = df_transformed['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (712, 5)\n",
      "The shape of X_test is (179, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of X_train is {X_train.shape}')\n",
    "print(f'The shape of X_test is {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Train Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76       105\n",
      "           1       0.66      0.70      0.68        74\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.72      0.72      0.72       179\n",
      "weighted avg       0.73      0.73      0.73       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "log_reg = LogisticRegression(C=1, solver='liblinear', class_weight='balanced')\n",
    "pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('classifier', log_reg)          # Model training\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.75       105\n",
      "           1       0.64      0.72      0.68        74\n",
      "\n",
      "    accuracy                           0.72       179\n",
      "   macro avg       0.71      0.72      0.71       179\n",
      "weighted avg       0.72      0.72      0.72       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=30, max_depth=3, class_weight='balanced')\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('classifier', rf_clf)          # Model training\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "pipeline2.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "y_pred = pipeline2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Train Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.64      0.69       105\n",
      "           1       0.58      0.72      0.64        74\n",
      "\n",
      "    accuracy                           0.67       179\n",
      "   macro avg       0.67      0.68      0.67       179\n",
      "weighted avg       0.69      0.67      0.67       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVC = SVC(class_weight='balanced')\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Feature scaling\n",
    "            ('SVC', SVC)          # Model training\n",
    "        ])\n",
    "\n",
    "        # Train the model\n",
    "pipeline3.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "y_pred = pipeline3.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"LR Normal\", \n",
    "        {},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"LR With params\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(C=1, solver='liblinear', class_weight='balanced'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"RF Normal\", \n",
    "        {},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"RF With params\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3, \"class_weight\":'balanced'},\n",
    "        RandomForestClassifier(n_estimators=30, max_depth=3, class_weight='balanced'), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: LR Normal\n",
      "{'0': {'precision': 0.7175572519083969, 'recall': 0.8952380952380953, 'f1-score': 0.7966101694915254, 'support': 105.0}, '1': {'precision': 0.7708333333333334, 'recall': 0.5, 'f1-score': 0.6065573770491803, 'support': 74.0}, 'accuracy': 0.7318435754189944, 'macro avg': {'precision': 0.7441952926208651, 'recall': 0.6976190476190476, 'f1-score': 0.7015837732703529, 'support': 179.0}, 'weighted avg': {'precision': 0.7395820006539015, 'recall': 0.7318435754189944, 'f1-score': 0.7180408586494387, 'support': 179.0}}\n",
      "#################################\n",
      "\n",
      "Model name: LR With params\n",
      "{'0': {'precision': 0.7175572519083969, 'recall': 0.8952380952380953, 'f1-score': 0.7966101694915254, 'support': 105.0}, '1': {'precision': 0.7708333333333334, 'recall': 0.5, 'f1-score': 0.6065573770491803, 'support': 74.0}, 'accuracy': 0.7318435754189944, 'macro avg': {'precision': 0.7441952926208651, 'recall': 0.6976190476190476, 'f1-score': 0.7015837732703529, 'support': 179.0}, 'weighted avg': {'precision': 0.7395820006539015, 'recall': 0.7318435754189944, 'f1-score': 0.7180408586494387, 'support': 179.0}}\n",
      "#################################\n",
      "\n",
      "Model name: RF Normal\n",
      "{'0': {'precision': 0.7387387387387387, 'recall': 0.780952380952381, 'f1-score': 0.7592592592592593, 'support': 105.0}, '1': {'precision': 0.6617647058823529, 'recall': 0.6081081081081081, 'f1-score': 0.6338028169014085, 'support': 74.0}, 'accuracy': 0.7094972067039106, 'macro avg': {'precision': 0.7002517223105458, 'recall': 0.6945302445302446, 'f1-score': 0.6965310380803339, 'support': 179.0}, 'weighted avg': {'precision': 0.7069170715243669, 'recall': 0.7094972067039106, 'f1-score': 0.7073945847649522, 'support': 179.0}}\n",
      "#################################\n",
      "\n",
      "Model name: RF With params\n",
      "{'0': {'precision': 0.8085106382978723, 'recall': 0.7238095238095238, 'f1-score': 0.7638190954773869, 'support': 105.0}, '1': {'precision': 0.6588235294117647, 'recall': 0.7567567567567568, 'f1-score': 0.7044025157232704, 'support': 74.0}, 'accuracy': 0.7374301675977654, 'macro avg': {'precision': 0.7336670838548185, 'recall': 0.7402831402831402, 'f1-score': 0.7341108056003287, 'support': 179.0}, 'weighted avg': {'precision': 0.7466288167471908, 'recall': 0.7374301675977654, 'f1-score': 0.7392558166963555, 'support': 179.0}}\n",
      "#################################\n",
      "\n",
      "Model name: SVC With params\n",
      "{'0': {'precision': 0.7551020408163265, 'recall': 0.7047619047619048, 'f1-score': 0.729064039408867, 'support': 105.0}, '1': {'precision': 0.6172839506172839, 'recall': 0.6756756756756757, 'f1-score': 0.6451612903225806, 'support': 74.0}, 'accuracy': 0.6927374301675978, 'macro avg': {'precision': 0.6861929957168051, 'recall': 0.6902187902187902, 'f1-score': 0.6871126648657238, 'support': 179.0}, 'weighted avg': {'precision': 0.6981269644211916, 'recall': 0.6927374301675978, 'f1-score': 0.6943779867139777, 'support': 179.0}}\n",
      "#################################\n",
      "\n",
      "Report for LR Normal:\n",
      "{'0': {'precision': 0.7175572519083969, 'recall': 0.8952380952380953, 'f1-score': 0.7966101694915254, 'support': 105.0}, '1': {'precision': 0.7708333333333334, 'recall': 0.5, 'f1-score': 0.6065573770491803, 'support': 74.0}, 'accuracy': 0.7318435754189944, 'macro avg': {'precision': 0.7441952926208651, 'recall': 0.6976190476190476, 'f1-score': 0.7015837732703529, 'support': 179.0}, 'weighted avg': {'precision': 0.7395820006539015, 'recall': 0.7318435754189944, 'f1-score': 0.7180408586494387, 'support': 179.0}}\n",
      "###############################\n",
      "Report for LR With params:\n",
      "{'0': {'precision': 0.7175572519083969, 'recall': 0.8952380952380953, 'f1-score': 0.7966101694915254, 'support': 105.0}, '1': {'precision': 0.7708333333333334, 'recall': 0.5, 'f1-score': 0.6065573770491803, 'support': 74.0}, 'accuracy': 0.7318435754189944, 'macro avg': {'precision': 0.7441952926208651, 'recall': 0.6976190476190476, 'f1-score': 0.7015837732703529, 'support': 179.0}, 'weighted avg': {'precision': 0.7395820006539015, 'recall': 0.7318435754189944, 'f1-score': 0.7180408586494387, 'support': 179.0}}\n",
      "###############################\n",
      "Report for RF Normal:\n",
      "{'0': {'precision': 0.7387387387387387, 'recall': 0.780952380952381, 'f1-score': 0.7592592592592593, 'support': 105.0}, '1': {'precision': 0.6617647058823529, 'recall': 0.6081081081081081, 'f1-score': 0.6338028169014085, 'support': 74.0}, 'accuracy': 0.7094972067039106, 'macro avg': {'precision': 0.7002517223105458, 'recall': 0.6945302445302446, 'f1-score': 0.6965310380803339, 'support': 179.0}, 'weighted avg': {'precision': 0.7069170715243669, 'recall': 0.7094972067039106, 'f1-score': 0.7073945847649522, 'support': 179.0}}\n",
      "###############################\n",
      "Report for RF With params:\n",
      "{'0': {'precision': 0.8085106382978723, 'recall': 0.7238095238095238, 'f1-score': 0.7638190954773869, 'support': 105.0}, '1': {'precision': 0.6588235294117647, 'recall': 0.7567567567567568, 'f1-score': 0.7044025157232704, 'support': 74.0}, 'accuracy': 0.7374301675977654, 'macro avg': {'precision': 0.7336670838548185, 'recall': 0.7402831402831402, 'f1-score': 0.7341108056003287, 'support': 179.0}, 'weighted avg': {'precision': 0.7466288167471908, 'recall': 0.7374301675977654, 'f1-score': 0.7392558166963555, 'support': 179.0}}\n",
      "###############################\n",
      "Report for SVC With params:\n",
      "{'0': {'precision': 0.7551020408163265, 'recall': 0.7047619047619048, 'f1-score': 0.729064039408867, 'support': 105.0}, '1': {'precision': 0.6172839506172839, 'recall': 0.6756756756756757, 'f1-score': 0.6451612903225806, 'support': 74.0}, 'accuracy': 0.6927374301675978, 'macro avg': {'precision': 0.6861929957168051, 'recall': 0.6902187902187902, 'f1-score': 0.6871126648657238, 'support': 179.0}, 'weighted avg': {'precision': 0.6981269644211916, 'recall': 0.6927374301675978, 'f1-score': 0.6943779867139777, 'support': 179.0}}\n",
      "###############################\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define models with pipelines\n",
    "models = [\n",
    "    (\n",
    "        \"LR Normal\", \n",
    "        {},\n",
    "        Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression())]), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"LR With params\", \n",
    "        {\"LR__C\": 1, \"LR__solver\": 'liblinear'},\n",
    "        Pipeline([('scaler', StandardScaler()), ('LR', LogisticRegression())]), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"RF Normal\", \n",
    "        {},\n",
    "        Pipeline([('scaler', StandardScaler()), ('RF', RandomForestClassifier())]), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"RF With params\", \n",
    "        {\"RF__n_estimators\": 30, \"RF__max_depth\": 3, \"RF__class_weight\": 'balanced'},\n",
    "        Pipeline([('scaler', StandardScaler()), ('RF', RandomForestClassifier())]), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"SVC With params\", \n",
    "        {\"SVC__C\": 1, \"SVC__kernel\": 'linear', \"SVC__class_weight\": 'balanced'},\n",
    "        Pipeline([('scaler', StandardScaler()), ('SVC', SVC())]), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "]\n",
    "\n",
    "reports = []\n",
    "\n",
    "for model_name, params, pipeline, (X_train, y_train), (X_test, y_test) in models:\n",
    "    print(f'Model name: {model_name}')\n",
    "    \n",
    "    # Set model-specific parameters if provided\n",
    "    if params:\n",
    "        pipeline.set_params(**params)\n",
    "\n",
    "    # Fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Generate and print the classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    print(report)\n",
    "    print(f'#################################\\n')\n",
    "    \n",
    "    # Append the report to the list\n",
    "    reports.append((model_name, report))\n",
    "\n",
    "# Optionally, you can print out the reports\n",
    "for model_name, report in reports:\n",
    "    print(f\"Report for {model_name}:\")\n",
    "    print(report)\n",
    "    print(f\"###############################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:23:08 INFO mlflow.tracking.fluent: Experiment with name 'Titanic_Survival_Prediction' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/191165618774552540', creation_time=1738869788246, experiment_id='191165618774552540', last_update_time=1738869788246, lifecycle_stage='active', name='Titanic_Survival_Prediction', tags={}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Set or create experiment if necessary\n",
    "mlflow.set_experiment('Titanic_Survival_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:25:29 INFO mlflow.tracking.fluent: Experiment with name 'Titanics Detections' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:25:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run LR Normal at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/9f666a34ebdd469db61b226a21040f5b\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:25:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run LR With params at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/315190e4e3984b17931b377b32b8d067\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:25:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run RF Normal at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/41f99c19243f4e7782c6dac506b1b748\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:26:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run RF With params at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/8c4d2ecbaf684506ae542ca426f69ac3\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/06 22:26:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run SVC With params at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/c1548e7474d2477da6b75312ae698858\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Titanics Detection\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    pipeline = element[2]\n",
    "    (X_train, y_train), (X_test, y_test) = element[3], element[4]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Set model-specific parameters\n",
    "        if params:\n",
    "            pipeline.set_params(**params)\n",
    "        \n",
    "        # Fit the model pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        # Generate classification report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Log the parameters\n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        # Log the metrics (handling edge cases for class imbalance)\n",
    "        metrics = {\n",
    "            'accuracy': report['accuracy'],\n",
    "            'precision_class_1': report['1']['precision'] if '1' in report else 0,\n",
    "            'precision_class_0': report['0']['precision'] if '0' in report else 0,\n",
    "            'recall_class_1': report['1']['recall'] if '1' in report else 0,\n",
    "            'recall_class_0': report['0']['recall'] if '0' in report else 0,\n",
    "            'f1_score_class_1': report['1']['f1-score'] if '1' in report else 0,\n",
    "            'f1_score_class_0': report['0']['f1-score'] if '0' in report else 0,\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        }\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log the model based on type\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(pipeline, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(pipeline, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'LR With params'.\n",
      "2025/02/06 22:28:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LR With params, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run LR With params at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/315190e4e3984b17931b377b32b8d067\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n",
      "Model registered with name: LR With params and run ID: 315190e4e3984b17931b377b32b8d067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'LR With params'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LR With params'  \n",
    "run_id = input('Please type RunID: ')  \n",
    "\n",
    "# Form the model URI from the run ID\n",
    "model_uri = f'runs:/{run_id}/model' \n",
    "\n",
    "# Register the model\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "print(f\"Model registered with name: {model_name} and run ID: {run_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 4 predictions: [0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# After registration, use the model name and version to load the model\n",
    "model_version = 1\n",
    "\n",
    "# model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "# Load the registered model\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Display the first 4 predictions\n",
    "print(\"First 4 predictions:\", y_pred[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 4 probabilities for class 1: [0.24568529 0.40657272 0.29246188 0.67636816]\n"
     ]
    }
   ],
   "source": [
    "# Get predicted probabilities\n",
    "y_pred_proba = loaded_model.predict_proba(X_test)\n",
    "\n",
    "# Show the first 4 probabilities (for class 1)\n",
    "print(\"First 4 probabilities for class 1:\", y_pred_proba[:4, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7318435754189944\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       105\n",
      "           1       0.77      0.50      0.61        74\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.74      0.70      0.70       179\n",
      "weighted avg       0.74      0.73      0.72       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model (e.g., using accuracy and classification report)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Generate a classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run luxuriant-fowl-680 at: http://127.0.0.1:5000/#/experiments/521150557808231275/runs/b191600ea976452d961d85f2e7e3ec15\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/521150557808231275\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80       105\n",
      "           1       0.77      0.50      0.61        74\n",
      "\n",
      "    accuracy                           0.73       179\n",
      "   macro avg       0.74      0.70      0.70       179\n",
      "weighted avg       0.74      0.73      0.72       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the classification report to a file\n",
    "report_filename = \"classification_report.txt\"\n",
    "with open(report_filename, \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Log the metrics and report to MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_artifact(report_filename)  \n",
    "\n",
    "# Optionally, print the report\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
